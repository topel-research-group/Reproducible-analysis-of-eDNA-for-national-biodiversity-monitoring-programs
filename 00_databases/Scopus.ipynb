{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybliometrics.scopus import ScopusSearch\n",
    "from lib.Publications import Publication\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bug seems to prevent the library to locate the API key.\n",
    "# This might help.\n",
    "! export PYB_CONFIG_FILE=~/.pybliometrics/config.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search string to use. Any query that works on Advanced Search\n",
    "# https://www.scopus.com/search/form.uri?display=advanced will also work here.\n",
    "# https://www.scopus.com/results/results.uri?sort=plf-f&src=s&st1=%28%22eDNA%22+OR+%22environmental+DNA%22+OR+%22metabarcoding%22+OR+%22eRNA%22+OR+%22environmental+RNA%22%29+AND+%28%22biodiversity%22+OR+%22species+richness%22+OR+%22monitoring%22+OR+%22biomonitoring%22%29+AND+%28%22high+throughput+sequencing%22+OR+%22HTS%22+OR+%22throughput%22%29&sid=12444d4a686dbf3e9b7379c820258783&sot=b&sdt=b&sl=236&s=TITLE-ABS-KEY%28%28%22eDNA%22+OR+%22environmental+DNA%22+OR+%22metabarcoding%22+OR+%22eRNA%22+OR+%22environmental+RNA%22%29+AND+%28%22biodiversity%22+OR+%22species+richness%22+OR+%22monitoring%22+OR+%22biomonitoring%22%29+AND+%28%22high+throughput+sequencing%22+OR+%22HTS%22+OR+%22throughput%22%29%29&origin=searchbasic&editSaveSearch=&yearFrom=Before+1960&yearTo=Present\n",
    "query = 'TITLE-ABS-KEY ((\"eDNA\" OR \"environmental DNA\" OR \"metabarcoding\" OR \"eRNA\" OR \"environmental RNA\") AND (\"biodiversity\" OR \"species richness\" OR \"monitoring\" OR \"biomonitoring\") AND (\"high throughput sequencing\" OR \"HTS\" OR \"throughput\"))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading results for query \"TITLE-ABS-KEY ((\"eDNA\" OR \"environmental DNA\" OR \"metabarcoding\" OR \"eRNA\" OR \"environmental RNA\") AND (\"biodiversity\" OR \"species richness\" OR \"monitoring\" OR \"biomonitoring\") AND (\"high throughput sequencing\" OR \"HTS\" OR \"throughput\"))\":\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:36<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# ScopusSearch(query, \n",
    "#              refresh=False, \n",
    "#              view=None, \n",
    "#              verbose=False, \n",
    "#              download=True, \n",
    "#              integrity_fields=None, \n",
    "#              integrity_action='raise', \n",
    "#              subscriber=True, **kwds)\n",
    "# https://pybliometrics.readthedocs.io/en/stable/classes/ScopusSearch.html\n",
    "\n",
    "search = ScopusSearch(query, refresh=True, view=\"COMPLETE\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# More information about the atributes of the result can be found at\\n# https://dev.elsevier.com/sc_search_views.html \\n# Title\\nprint(search.results[0].title)\\n\\n# Author keywords\\nkeywords = []\\nfor i in search.results[0].authkeywords.split(\"|\"):\\n    keywords.append(i.strip())\\nprint(keywords)\\n\\n# Abstract\\nprint(search.results[0].description)\\n\\n# DOI\\nprint(search.results[0].doi)\\n\\n# eid\\nprint(search.results[0].eid)\\n\\n# pii\\nprint(search.results[0].pii)\\n\\n# Journal\\nprint(search.results[0].publicationName)\\n\\n# Date\\nprint(search.results[0].coverDate)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# More information about the atributes of the result can be found at\n",
    "# https://dev.elsevier.com/sc_search_views.html \n",
    "# Title\n",
    "print(search.results[0].title)\n",
    "\n",
    "# Author keywords\n",
    "keywords = []\n",
    "for i in search.results[0].authkeywords.split(\"|\"):\n",
    "    keywords.append(i.strip())\n",
    "print(keywords)\n",
    "\n",
    "# Abstract\n",
    "print(search.results[0].description)\n",
    "\n",
    "# DOI\n",
    "print(search.results[0].doi)\n",
    "\n",
    "# eid\n",
    "print(search.results[0].eid)\n",
    "\n",
    "# pii\n",
    "print(search.results[0].pii)\n",
    "\n",
    "# Journal\n",
    "print(search.results[0].publicationName)\n",
    "\n",
    "# Date\n",
    "print(search.results[0].coverDate)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of results found for this search string\n",
    "search.get_results_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the result in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the search result to a Pandas dataframe \n",
    "#import pandas as pd\n",
    "#df = pd.DataFrame(search.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Find papers with specific keywords\\nimport numpy as np\\n\\nkeyword = \"zeta diversity\"\\ndf[df.authkeywords.str.contains(keyword).replace(np.nan, False)]\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Find papers with specific keywords\n",
    "import numpy as np\n",
    "\n",
    "keyword = \"zeta diversity\"\n",
    "df[df.authkeywords.str.contains(keyword).replace(np.nan, False)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sys\\nsys.setrecursionlimit(15000)\\n\\n# Recursive flattening of \"list of lists\"\\n# https://stackabuse.com/python-how-to-flatten-list-of-lists/\\ndef flatten_list(list_of_lists):\\n    if len(list_of_lists) == 0:\\n        return list_of_lists\\n    if isinstance(list_of_lists[0], list):\\n        return flatten_list(list_of_lists[0]) + flatten_list(list_of_lists[1:])\\n    return list_of_lists[:1] + flatten_list(list_of_lists[1:])\\n\\n# Combine all keywords in a list of lists\\nregular_list = df.authkeywords.str.split(\"|\").to_list()\\n# Flatten the list of lists\\nfl = flatten_list(regular_list)\\n# Remove leading and trailing white space from keywords\\nfl = [str(i).strip() for i in fl]\\n\\n# Count the keywords\\ncount = {}\\nfor i in fl:\\n    i = str(i)\\n    try:\\n        count[i] += 1\\n    except:\\n        count[i] = 1\\n\\n# Turn the dictionary of keywords into a Pandas dataframe\\nkw = pd.DataFrame.from_dict(count, orient=\\'index\\')\\n\\n# Display the 20 top keywords\\nkw.sort_values(0, ascending=False).head(20)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import sys\n",
    "sys.setrecursionlimit(15000)\n",
    "\n",
    "# Recursive flattening of \"list of lists\"\n",
    "# https://stackabuse.com/python-how-to-flatten-list-of-lists/\n",
    "def flatten_list(list_of_lists):\n",
    "    if len(list_of_lists) == 0:\n",
    "        return list_of_lists\n",
    "    if isinstance(list_of_lists[0], list):\n",
    "        return flatten_list(list_of_lists[0]) + flatten_list(list_of_lists[1:])\n",
    "    return list_of_lists[:1] + flatten_list(list_of_lists[1:])\n",
    "\n",
    "# Combine all keywords in a list of lists\n",
    "regular_list = df.authkeywords.str.split(\"|\").to_list()\n",
    "# Flatten the list of lists\n",
    "fl = flatten_list(regular_list)\n",
    "# Remove leading and trailing white space from keywords\n",
    "fl = [str(i).strip() for i in fl]\n",
    "\n",
    "# Count the keywords\n",
    "count = {}\n",
    "for i in fl:\n",
    "    i = str(i)\n",
    "    try:\n",
    "        count[i] += 1\n",
    "    except:\n",
    "        count[i] = 1\n",
    "\n",
    "# Turn the dictionary of keywords into a Pandas dataframe\n",
    "kw = pd.DataFrame.from_dict(count, orient='index')\n",
    "\n",
    "# Display the 20 top keywords\n",
    "kw.sort_values(0, ascending=False).head(20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore abstracts in html format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write title, Elsevier ID, keywords and Abstract to an html file\n",
    "#original_abstracts = open(\"original_abstracts.html\", \"w\")\n",
    "\n",
    "publications = []\n",
    "\n",
    "with open(\"original_abstracts_Scopus.html\", \"w\") as file:\n",
    "    for paper in search.results:\n",
    "        title = \"<h1>\" + paper.title + \"</h1>\" + \"\\n\"\n",
    "        title_obj = paper.title\n",
    "        eid = \"<p>\" + paper.eid + \"</p>\" + \"\\n\"\n",
    "        identifyer_obj = paper.eid\n",
    "        \n",
    "        try:\n",
    "            doi = \"<p><a href=\\\"https://doi.org/\" + paper.doi + \"\\\">\" + \"doi:\" + paper.doi + \"</a></p>\" + \"\\n\"\n",
    "            doi_obj = paper.doi\n",
    "        except TypeError:\n",
    "            doi = \"<p>No DOI</p>\"\n",
    "            doi_obj = None\n",
    "            \n",
    "        if paper.authkeywords is None:\n",
    "            keywords = \"<p>No keywords</p>\"\n",
    "            keywords_obj = None\n",
    "        else:\n",
    "            keywords = paper.authkeywords\n",
    "            keywords_obj = paper.authkeywords\n",
    "            \n",
    "        abstract = \"<p>\" + str(paper.description) + \"</p>\" + \"\\n\"\n",
    "        abstract_obj = paper.description\n",
    "        \n",
    "        publications.append(Publication(title = str(title_obj), doi = str(doi_obj), abstract = str(abstract_obj)))\n",
    "        string = title + eid + doi + keywords + abstract\n",
    "        \n",
    "        file.write(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download fulltext results in XML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pybliometrics.scopus\n",
    "#import requests\n",
    "#\n",
    "## Option 1.\n",
    "#\n",
    "#for paper in search.results:\n",
    "#    doi = paper.doi\n",
    "#    r = requests.get(f\"https://api.elsevier.com/content/article/doi/{doi}?apiKey={pybliometrics.scopus.KEYS[0]}\")\n",
    "#    print(str(r.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result to binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result to a binary file, and analyse it together with data from other searches.\n",
    "pickle.dump(publications, open(\"scopus.p\" ,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
