{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xsearch - Libris/SwePub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "from lib.Publications import Publication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"eDNA\"\n",
    "#query = '(\"eDNA\" OR \"environmental DNA\" OR \"metabarcoding\" OR \"eRNA\" OR \"environmental RNA\") AND (\"biodiversity\" OR \"species richness\" OR \"monitoring\" OR \"biomonitoring\") AND (\"high throughput sequencing\" OR \"HTS\" OR \"throughput\")'\n",
    "# Query Libris or SwePub\n",
    "db = \"swepub\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Libris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_db(query, start=1):\n",
    "    # http://librishelp.libris.kb.se/help/xsearch_swe.jsp?open=tech\n",
    "    return requests.get(f'https://libris.kb.se/xsearch?query={query}&order=alphabetical&format=json&start={start}&n=200&format_level=full&database={db}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 342\n",
      "Range: 201 - 342\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of records to retreive when using Xsearch is 200.\n",
    "# This loop will download all records if this limit is exceded.\n",
    "\n",
    "# Make the first database search\n",
    "start = 1\n",
    "results = []\n",
    "r = search_db(query)\n",
    "results.append(r)\n",
    "\n",
    "# Number of records\n",
    "print(f\"Records: {list(r.json().items())[0][1]['records']}\")\n",
    "\n",
    "# Make subsequent searches if the query returned more then 200 records\n",
    "while int(list(r.json().items())[0][1]['to']) < int(list(r.json().items())[0][1]['records']):\n",
    "    start += 200\n",
    "    r = search_db(query, start)\n",
    "    results.append(r)\n",
    "    print(f\"Range: {str(list(r.json().items())[0][1]['from'])} - {str(list(r.json().items())[0][1]['to'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identifier': 'http://swepub.kb.se/bib/swepub:oai:DiVA.org:lnu-805', 'title': 'Effect of fish and mesozooplankton manipulation on the phytoplankton community in the Patos Lagoon Estuary, Southern Brazil', 'creator': ['Abreu, P C', 'Granéli, Edna', 'Odebrecht, C', 'Kitzmann, D', 'Proença, L A', 'Resgalla Jr, C', 'Högskolan i Kalmar Naturvetenskapliga institutionen'], 'type': 'article', 'publisher': '', 'date': '1994', 'language': 'eng', 'subject': ['Akvatisk ekologi', 'Aquatic Ecology'], 'relation': 'Estuaries'}\n",
      "Effect of fish and mesozooplankton manipulation on the phytoplankton community in the Patos Lagoon Estuary, Southern Brazil\n",
      "article\n",
      "http://swepub.kb.se/bib/swepub:oai:DiVA.org:lnu-805\n"
     ]
    }
   ],
   "source": [
    "for x in list(results[0].json().items())[0][1]['list']:\n",
    "    print(x)\n",
    "    break\n",
    "\n",
    "    \n",
    "# Title\n",
    "print(x['title'])\n",
    "\n",
    "# Type of media\n",
    "print(x['type'])\n",
    "\n",
    "# Keywords\n",
    "\n",
    "# Abstract\n",
    "try:\n",
    "    print(x['description'])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# DOI\n",
    "\n",
    "# Identifier\n",
    "print(x['identifier'])\n",
    "\n",
    "# eid\n",
    "\n",
    "# pii\n",
    "\n",
    "# Journal\n",
    "\n",
    "# Date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore abstracts in html format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'description' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b9f3cf3f6aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midentity\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmedia_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mpublications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPublication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifyer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'identifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'description' is not defined"
     ]
    }
   ],
   "source": [
    "publications = []\n",
    "\n",
    "with open(\"original_abstracts_\" + db + \".html\", \"w\") as file:\n",
    "    for result in results:\n",
    "        for media in list(result.json().items())[0][1]['list']:\n",
    "        \n",
    "            media_list = ['book', 'article', 'E-book', 'E-article']\n",
    "            # Only look at books and articles\n",
    "            if media['type'] in media_list:        \n",
    "        \n",
    "                title = \"<h1>\" + media[\"title\"] + \"</h1>\" + \"\\n\"\n",
    "        \n",
    "                identity = \"<p><a href=\" + \\\n",
    "                            media['identifier'] + \\\n",
    "                            \">\" + \\\n",
    "                            media['identifier'] + \\\n",
    "                            \"</a></p>\" + \\\n",
    "                            \"\\n\"\n",
    "                media_type = media[\"type\"]\n",
    "            \n",
    "                # First make sure there is a description for this item,\n",
    "                # then concatenate the list of descriptions if needed.\n",
    "                \n",
    "                try:\n",
    "                    media['description'] == True\n",
    "                    if type(media['description']) == list:\n",
    "                        description = \"\"\n",
    "                        for i in range(len(media['description'])):\n",
    "                            description += str(media['description'][i] + \"</p><p>\")\n",
    "                    elif type(media['description']) == str:\n",
    "                        description = media['description']\n",
    "            \n",
    "                    abstract = \"<p>\" + \\\n",
    "                                description + \\\n",
    "                                \"</p>\" + \\\n",
    "                                \"\\n\"\n",
    "                except:    \n",
    "                    abstract = \"<p>No Abstract</p>\"\n",
    "        \n",
    "                string = title + identity + media_type + abstract\n",
    "            \n",
    "                publications.append(Publication(title = media[\"title\"], identifyer = media['identifier'], abstract = description))\n",
    "        \n",
    "                file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method of writing the result in html format\n",
    "# after data has been stores as Publication objects.\n",
    "with open(\"test.html\", \"w\") as file:\n",
    "    for i in publications:\n",
    "        file.write(i.to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save result to binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result to a binary file, and analyse it together with data from other searches.\n",
    "pickle.dump(publications, open(db + \"_eDNA.p\" ,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
